{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LM_ONLINE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZfdSDPOvGXBW8t40FyCSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h-aldarmaki/NLPCourse/blob/main/Language_Models_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X8YSiK3JkCh"
      },
      "source": [
        "# *n*-gram Language Models\n",
        "\n",
        "In this exercise, you will learn how to implement *n*-gram language models, use them to calculate sentence probabilities, and generate text from the LM distribution. The implementation is meant to be straightforward and intuitive, not necessarily efficient. \n",
        "\n",
        "##**What you will do:**\n",
        "\n",
        "\n",
        "1.   Follow the steps in this notebook and read all lines of code and comments to understand what's happening. \n",
        "2.   Answer questions and complete the code where required (questions are marked as \"**Exercise**\")\n",
        "3.   Submit your final implementation (as **Pdf** + sharable link) and a sample of generated text from bigram and trigram models. \n",
        "4.   **[Optional - Bonus 2 points]** Train an LM on a different dataset of your choice. Use it to generate new sentences. Describe the additional steps you used to normalize the dataset. \n",
        "\n",
        "\n",
        "##**What you will need:**\n",
        "\n",
        "We will use the following python packages: \n",
        "\n",
        "\n",
        "*   nltk\n",
        "*   re\n",
        "*   numpy\n",
        "*   pandas\n",
        "\n",
        "Remind yourself of regular expressions and numpy functions from previous exercises.\n",
        "\n",
        "\n",
        "### **Data Structures:**\n",
        "To conveniently store n-grams statistics, we will use the  ```freqDist``` class from NLTK \n",
        "https://www.kite.com/python/docs/nltk.FreqDist\n",
        "\n",
        "We will also use the ```bigrams``` and ```ngram``` functions from NLTK:\n",
        "https://www.kite.com/python/answers/how-to-split-a-string-into-n-grams-in-python \n",
        "\n",
        "And we will use ```Pandas.DataFrame``` for sampling from n-gram distributions\n",
        "\n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
        "\n",
        "\n",
        "\n",
        "###**The Dataset**\n",
        "\n",
        "The Berkeley Restaurant Project (BeRP) dataset contains about 7 hours of recorded utterances that were collected for the purpose of designing a speech recognition system for restaurant recommendations in the city of Berkeley, California. We will use the text transcripts for training our model.  \n",
        "\n",
        "\n",
        "#Steps:\n",
        "\n",
        "Download the dataset and inspect the file berp-trans/transcript.txt. Note that the transcripts are already tokenized but there are some additional notations, like the audio file name and pause fillers such as [uh] [um] etc. Process the data by removing the filename and any such codes, i.e. everything between < > or [ ]. Later, we will add \\<s\\> and \\</s\\> tags to identify beginning and end of sentences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2_iN0bhJEmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf5a8da-5860-4bf8-cae7-e18db6fd16ba"
      },
      "source": [
        "# download the dataset\n",
        "! git clone https://github.com/wooters/berp-trans.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'berp-trans'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Total 22 (delta 0), reused 0 (delta 0), pack-reused 22\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHmnRpypKExf"
      },
      "source": [
        "# Inspecct the first 10 lines\n",
        "! head berp-trans/transcript.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTcUAkxmlQNZ"
      },
      "source": [
        "#**Part 1**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2lJHS2qKEUf"
      },
      "source": [
        "#Process Dataset\n",
        "\n",
        "First, we will read the dataset and apply regular expressions to remove the unwanted tags. \n",
        "\n",
        "**Exercise:** Complete the code below by adding the missing statements in the while loop. Check the output to make sure the processing is done correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTCL98Y-yhtK"
      },
      "source": [
        "import re\n",
        "\n",
        "#Let's first read the file\n",
        "filename ='berp-trans/transcript.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "#split sentences\n",
        "text = text.split('\\n')\n",
        "\n",
        "print(text[:10])\n",
        "\n",
        "i=0\n",
        "while i < len(text):\n",
        "  #TODO Apply a regular expression to remove the first word from each line (e.g. 33_1_0001)\n",
        "\n",
        "\n",
        "  #TODO Apply a regular expression to remove all HTML tags and pause fillers -- anything between square [ ]  and angled < > brackets \n",
        "\n",
        "\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "print(text[:10])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgPzntmgb2Nk"
      },
      "source": [
        "#  Dataset Division\n",
        "\n",
        "Next, we will split the dataset into train and test parts. Most of the data will be used for training, and a small fraction is held out for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrd3RkGrKGyB"
      },
      "source": [
        "#Let's now divide the dataset into Train and Test sets\n",
        "\n",
        "print(len(text))\n",
        "\n",
        "#I'll keep the first 8000 sentences for training, and the rest for testing ...\n",
        "\n",
        "trainset = text[0:8000]\n",
        "testset = text[8000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLeFr-W_cG8s"
      },
      "source": [
        "#Unigram Distribution\n",
        "\n",
        "Next, we will caclulate the distribution of the unigrams (i.e. the words) in the training set. We will add \\<s\\> and \\</s\\> tags to identify beginning and end of sentences. FreqDist() will be used for convenience. Alternatively, we could use a python dictionary to store the unique tokens and their counts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_eWBgsS4yjx"
      },
      "source": [
        "import nltk\n",
        "\n",
        "#create FreqDist object\n",
        "unigram_dist = nltk.FreqDist()\n",
        "for sen in trainset:\n",
        "  #add sentence boundary tags\n",
        "  sen = \"<s> \"+ sen +\" </s>\"\n",
        "  #Update the frequency distribution (sen.split() will split the sentnece into words)\n",
        "  unigram_dist.update(sen.split())\n",
        "\n",
        "#print the 10 most common unigrams:\n",
        "print(unigram_dist.most_common(10))\n",
        "\n",
        "#Total number of tokens, including the added <s> and </s> tags\n",
        "print(unigram_dist.N())\n",
        "\n",
        "#count for the word 'like'\n",
        "print(unigram_dist.get('like'))\n",
        "\n",
        "#relative frequency (probability) of the unigram 'like'\n",
        "print(unigram_dist.freq('like'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYvv-cc4m-RJ"
      },
      "source": [
        "#Bigram Distribution\n",
        "\n",
        "Next, we will caclulate the distribution of the bigrams (i.e. two consecutive words) in the training set. Again, we will add \\<s\\> and \\</s\\> tags to identify beginning and end of sentences. We will use ```nltk.bigrams ``` to get a list of all bigrams in each sentence. FreqDist() will be used to store the counts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOOc6AxinepJ"
      },
      "source": [
        "#nltk.bigrams returns a list of bigrams. \n",
        "#We could alternatively use nltk.ngrams, and specify the order n in the parameters\n",
        "\n",
        "import nltk\n",
        "sentence = trainset[0]\n",
        "print(sentence.split())\n",
        "for bigram in nltk.bigrams(sentence.split()):\n",
        " print(bigram)\n",
        "\n",
        "for trigram in nltk.ngrams(sentence.split(), 3):\n",
        "  print(trigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7I3mvBUAji8"
      },
      "source": [
        "#get all bigrams from the corpus, then add them to frequency distribution\n",
        "bigram_dist = nltk.FreqDist()\n",
        "for sen in trainset:\n",
        "  sen = \"<s> \"+sen+\" </s>\"\n",
        "  bigrams = nltk.bigrams(sen.split())\n",
        "  bigram_dist.update(bigrams)\n",
        "\n",
        "#print the most common bigrams\n",
        "print(bigram_dist.most_common(10))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncsagl8mo2Zc"
      },
      "source": [
        "#Calculating Sentence Probability\n",
        "\n",
        "**Exercise:** Given the n-gram distributions above, write code for calculating the following:\n",
        "\n",
        "1.   P('i')\n",
        "2.   P('want' | 'i')\n",
        "3.   P('\\<s\\> i want to go to an italian restaurant \\</s\\>')\n",
        "\n",
        "**Exercise:** Complete the implementation of the function sentence_prob(sen), which should take any string ```s``` and return its probability. Assume the string does not contain the \\<s\\> and \\</s\\> tags, but you need to include them in the calculation. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xez8-MkXrfVO"
      },
      "source": [
        "# 1. calculate and print P('i')\n",
        "\n",
        "\n",
        "# 2.  calculate and print P('want' | 'i')\n",
        "\n",
        "\n",
        "# 3. calculate and print P('<s> i want to go to an italian restaurant </s>')\n",
        "\n",
        "\n",
        "# 4. Complete the implementation of the following function. \n",
        "# Then test it using the string \"i want to go to an italian resurant\"\n",
        "# You should get the same value as in (3.)\n",
        "def sentence_prob(s):\n",
        "  #your code here\n",
        "\n",
        "p=sentence_prob(\"i want to go to an italian restaurant\")\n",
        "#formatted print:\n",
        "print(f'p={p:.20f}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGBkNLSgvtJe"
      },
      "source": [
        "Note that multiplying probabilities quickly leads to very small values. This can become problematic in practice; for example, if we try to calculate the probability of the whole dataset, we can run into an underflow error. It is better to use log probabilities instead and sum their values. \n",
        "\n",
        "**Exercise:** Complete the implementation of the function log_prob(sen), which should take any string ```s``` and return its log probability. Assume the string does not contain the \\<s\\> and \\</s\\> tags, but you need to include them in the calculation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLLtfb_KxKVz"
      },
      "source": [
        "import numpy as np\n",
        "def log_prob(s):\n",
        "  #Add your code here\n",
        "  \n",
        "\n",
        "print(log_prob(\"i want to go to an italian restaurant\"))\n",
        "p=np.power(2, log_prob(\"i want to go to an italian restaurant\"))\n",
        "print(f'p={p:.20f}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCn8NeFpCvmt"
      },
      "source": [
        "##What is encoded in n-grams?\n",
        "\n",
        "Now that you know how to calculate probabilities, let's try to figure out what kind of knowledge is encoded in this simple model. The dataset is about restaurant recommendations in Berkeley, California. Which do you think is more popular, Chinese or russian food?\n",
        "\n",
        "**Exercise:** Which of the following two sentences has higher probability? Use the functions you developed above to calculate and compare these probabilities. \n",
        "\n",
        "* \"i want chinese food\"\n",
        "* \"i want russian food\"\n",
        "\n",
        "\n",
        "**Exercise:** Which of the following two sentences has higher probability? Use the functions you developed above to calculate and compare these probabilities. \n",
        "\n",
        "* \"i like to chinese food\"\n",
        "* \"i like to eat chinese food\"\n",
        "\n",
        "Notice that, since we multiply values that are less than one (or sum up negative values in the case of log_prob), longer sentences tend to have lower probability. However, the above example shows how a grammatical error can lead to lower probability since p(chinese|to) is very low!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibGVu48tElAS"
      },
      "source": [
        "#your code here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhi63FOhXemw"
      },
      "source": [
        "#Text Generation\n",
        "\n",
        "We will now use the language models we developed to have some fun. There are many applications of language model, such as text completion or text generation. All we need is a way to sample from a distribution. We can use ```DataFrame``` from the pandas package to conveniently sample from our n-gram distributions. The following few cells shows you how to sample from the unigram distribution; read the comments and the code to understand the steps you need to sample from a distribution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgMQ03bJXeOX"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#first, convert the unigram_dist object to a pd.DataFrame object:\n",
        "temp = pd.DataFrame(pd.Series(unigram_dist))\n",
        "\n",
        "#rename the columns \n",
        "temp.columns = ['counts']\n",
        "\n",
        "#Sort the values by count\n",
        "temp = temp.sort_values('counts', ascending=False)\n",
        "\n",
        "#Print the dataframe and note the most common unigrams\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtZFb3sUaQEW"
      },
      "source": [
        "# Sample 10 words from the unigram distribution. replace=True allows sampling the same words multiple timees ... \n",
        "# Run this multiple times and observe the output \n",
        "print(temp.sample(n=10, replace=True, weights='counts'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsqASUVqeo1_"
      },
      "source": [
        "\n",
        "# we can extract only the words:\n",
        "generated = temp.sample(n=10, replace=True, weights='counts')\n",
        "generated = generated.index.values\n",
        "for word in generated:\n",
        "    if word not in ['<s>', '</s>']:\n",
        "        print(word, end =\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgFAMuD1es0o"
      },
      "source": [
        "#For bigrams, we need to first extract the conditional distribution. \n",
        "# For example, if we want to sample words following the word \"like\", we need to\n",
        "  #find the counts of bigrams that start with \"like\" \n",
        "words=[]\n",
        "counts=[]\n",
        "for k,v in bigram_dist.items():\n",
        "  if k[0] == 'like': #check if bigram starts with 'like'\n",
        "    words.append(k[1])  #append the word following 'like' to the list of words\n",
        "    counts.append(v)\n",
        "\n",
        "like_dist = pd.DataFrame({'counts': counts}, index=words)\n",
        "like_dist = like_dist.sort_values('counts', ascending=False)\n",
        "print(like_dist)\n",
        "\n",
        "#Now we can sample a word from this distribution\n",
        "print(like_dist.sample(n=1, weights='counts'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMScB9nmcv-p"
      },
      "source": [
        "**Exercise:**\n",
        "\n",
        "\n",
        "\n",
        "1. Given the above hints, complete the implementation of the function: ```generate_from_bigrams```. The function takes one word, and it should return a word sampled from the bigram distribution. \n",
        "\n",
        "The rest of the code generates random sentences using this  function. Starting with the unigram \\<s\\>, it keeps generating new words until an \\</s\\> tag is generated, which marks the end of sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0GW_5eRe30Z"
      },
      "source": [
        "\n",
        "def generate_from_bigrams(word0):\n",
        "  #your code here\n",
        "\n",
        "\n",
        "i=0\n",
        "print(\"Sentences generated using bigram model:\\n\")\n",
        "while i<10:\n",
        "  word0=\"<s>\"\n",
        "  sen = \"\"\n",
        "  while True:\n",
        "    word1 = generate_from_bigrams(word0)\n",
        "    if word1 == \"</s>\":\n",
        "      break\n",
        "    sen =sen+\" \" +word1\n",
        "    word0 = word1\n",
        "\n",
        "  print(sen)\n",
        "  i=i+1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9UafLvIlBlr"
      },
      "source": [
        "#**Part 2**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW-Ho7uZEoYH"
      },
      "source": [
        "#Zero counts and smoothing\n",
        "\n",
        "**Exercise:** What is the probability of the following two sentences:\n",
        "\n",
        "* \"i want to eat egyptian food\"\n",
        "\n",
        "* \"i want to go to an egyptian restaurant\"\n",
        "\n",
        "The bigram \"egyptian restaurant\" does not exist in out dataset, so we get an error. We could easily fix that error by first checking if the bigram exist\n",
        "\n",
        "```\n",
        "if bigram_dist.get( (w0, s[i]) ) == None :\n",
        "   p = p * 0\n",
        "else \n",
        "   ...\n",
        "```\n",
        "\n",
        "However, this means that the whole sentence will have probability 0! this is not cool as we would like to calculate probabilities for all possible sentences, and it's not reasonable to assume that all valid bigrams would occur in the training dataset ... \n",
        "\n",
        "The solution is smoothing or backoff. Let's start by implementing add-1 smoothing. \n",
        "\n",
        "**Exercise:** Modify your log_prob function to implement add-1 smoothing for bigrams. Remember the formulas for calculating bigram probabilities:\n",
        "\n",
        "![c482641371ff01bdfde39bca8912b4da.png](data:image/png;base64,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)\n",
        "\n",
        "Where V is the vocabulary size. You can find the unique vocabulary items using ```unigram_dist.keys()```. Therefore, the size of the vocabulary can be calculated using the following line:\n",
        "\n",
        "```V = len(unigram_dist.keys() )```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0tL6hPxGlNm"
      },
      "source": [
        "#Re-implement log_prob(s) by incorporating add-1 smoothing\n",
        "def log_prob(s):\n",
        "  V = len(unigram_dist.keys())\n",
        "  #Add your code here\n",
        "  \n",
        "\n",
        "#then test the implementation:\n",
        "print(bigram_dist.get(('egyptian', 'food')))\n",
        "print(log_prob(\"i want to eat egyptian food\"))\n",
        "print(log_prob(\"i want to go to an egyptian restaurant\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhDkr6pEPVzh"
      },
      "source": [
        "#Unknown Words\n",
        "\n",
        "In the previous section, we handled unseen bigrams, but all the words in the sentence were already seen in the training set. What if we encounter a new word?\n",
        "\n",
        "For example, what is the probability of this sentence: \n",
        "\n",
        "* \"i want to eat emirati food\"\n",
        "\n",
        "The word \"emirati\" does not exist in our dataset, so this will cause an error. If we assign probability 0 to all new words, the whole sentence will have 0 probability, which is not what we want! \n",
        "\n",
        "One way to handle this is to assign some probability mass to unseen words. The most common way of doing that is to treat some words in the training set as unknown words. For example, we can take all words that occur only once in ```trainset``` and replace them with ```<unk>``` tag. This way, when we calculate the counts from the trainset, we will have a count for ```<unk>``` which we can then use to calculate the unigram and bigram probabilities for unseen words ... \n",
        "\n",
        "\n",
        "We can get the words that occur only once in the train set using the following function\n",
        "\n",
        "```unigram_dist.hapaxes()```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7wh7T-WPVVy"
      },
      "source": [
        "#print(log_prob(\"i want to emirati food\"))\n",
        "\n",
        "#hapaxes: words that occur only once\n",
        "hapaxes= unigram_dist.hapaxes()\n",
        "\n",
        "# Let's recalculate unigram_dist with <UNK> tags instead of hapaxes ... \n",
        "# At the same time, we will create a new dataset called \"new_train\" \n",
        "unigram_dist_unk = nltk.FreqDist()\n",
        "bigram_dist_unk = nltk.FreqDist()\n",
        "\n",
        "new_train = []\n",
        "for sen in trainset:\n",
        "  new_sen = \"<s>\"\n",
        "  words = sen.split()\n",
        "  for word in words:\n",
        "    if word in hapaxes:\n",
        "      new_sen = new_sen + \" <unk>\"\n",
        "    else:\n",
        "      new_sen = new_sen + \" \" + word\n",
        "  new_sen = new_sen+\" </s>\"\n",
        "  unigram_dist_unk.update(new_sen.split())\n",
        "  bigrams = nltk.bigrams(new_sen.split())\n",
        "  bigram_dist_unk.update(bigrams)\n",
        "  new_train.append(new_sen)\n",
        "      \n",
        "\n",
        "\n",
        "print(unigram_dist_unk.most_common(10))\n",
        "#Total count\n",
        "print(unigram_dist_unk.N())\n",
        "#count for the word 'like'\n",
        "print(unigram_dist_unk.get('like'))\n",
        "#unigram frequency of 'like'\n",
        "print(unigram_dist_unk.freq('like'))\n",
        "print(unigram_dist_unk.freq('<unk>'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROGpiWGOTavN"
      },
      "source": [
        "**Exercise**: Modify your log_prob function to include <unk> tags for unseen words. You can get a list of words already seen in the training set using the following\n",
        "\n",
        "```vocab = unigram_dist.keys()```\n",
        "\n",
        "Then, for each word in the sentence, you can check if it's in the voacbulary or not. If not, replace the word with \\<unk\\> to retrieve the correct count from ```unigram_dist_unk``` and ```bigram_dist_unk```. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoNpymaOR1N4"
      },
      "source": [
        "vocab = unigram_dist_unk.keys()\n",
        "\n",
        "#re-implement log_prob(s) by incorporating unknown words\n",
        "def log_prob(s):\n",
        "  #your code here\n",
        "  \n",
        "\n",
        "\n",
        "print(log_prob(\"i want to eat emirati food\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9G2Z11jT7TV"
      },
      "source": [
        "#Perplexity \n",
        "\n",
        "Now that we can handle unseen words and bigrams, we can calculate the perplexity of the dataset. Remember that the formula for perplexity is given by:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "However, it is better to deal with log probabilities, so you can use your log_prob function in the calculation and simply add up the log probabilities of all sentences in the dataset. To get the actual perplexity, \n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "**Exercise**:\n",
        "\n",
        "The following code shows how to calculate the perplexity for the training set. Use a similar code to calculate the perplexity of the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3WCMsditxTi"
      },
      "source": [
        "#Calculate dataset perplexity\n",
        "import numpy as np\n",
        "sum = 0\n",
        "N = 0\n",
        "for sen in trainset:\n",
        "  #calculate sum of log probabilities\n",
        "  words = sen.split()\n",
        "  if len(words) < 1:\n",
        "    continue\n",
        "  N = N + len(words)+2 # +2 for the <s> and </s> tags\n",
        "  sum = sum + log_prob(sen)\n",
        "\n",
        "print(sum/N)\n",
        "pp = np.power(2, -(sum/N))\n",
        "print(pp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYRHszXdsEFV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpQeFBSrX6Ei"
      },
      "source": [
        "#Trigram language model\n",
        "\n",
        "Now that you have experience with unigram and bigram models, you can handle longer n-grams. Implement a trigram language model for the dataset, and use it to compare probabilities of sentences, and to calculate the perplexity of the test set. If you cannot find counts for a specific trigram, backoff to the bigram probability (just call the approperiate function from above implementation). Use the new_train dataset which already has rare words replaced with \\<unk\\>\n",
        "\n",
        "**Exercise**:\n",
        "\n",
        "* Implement a trigram language model with backoff as described above. Use ```new_train``` dataset. \n",
        "* Implement a method ```log_prob_tri(s)``` for calculating a probability of a sentence using the trigram model. Use stupid backoff to handle cases where a trigram count is 0. \n",
        "* Report the perplexity of the test set using unigram, bigram, and trigram language models. Which model has the lowest perplexity? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JoxXB8jo1jC"
      },
      "source": [
        "#your code here:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obg9EaFoii-I"
      },
      "source": [
        "#**Text Generation**\n",
        "\n",
        "We will now use the trigram language model for text generation, as we did with bigrams. \n",
        "\n",
        "**Exercise:**\n",
        "\n",
        "1. Complete the implementation of the function ```generate_from_trigrams```. This function is similar to ```generate_from_bigrams```, but it searches the trigram distribution instead. It takes two words as arguments, and it should return the third word. You should be careful in the implementation, as some combinations of word0 and word1 might not exist. In that case, you need to back off to the bigram distribution (generate using word1 alone). \n",
        "\n",
        "\n",
        "The rest of the code generates random sentences using this function. Starting with the unigram \\<s\\>, then it keeps generating new words until an \\</s\\> tag is generated, which marks the end of sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIl_nFXEigzy"
      },
      "source": [
        "def generate_from_trigrams(word0, word1):\n",
        "  #your code here\n",
        "\n",
        "\n",
        "i=0\n",
        "print(\"\\n\\nSentences generated using trigram model:\\n\")\n",
        "while i<10:\n",
        "  word0=\"<s>\"\n",
        "  sen = \"\"\n",
        "  #1. generate first word from bigram distribution:\n",
        "  word1 = generate_from_bigrams(word0)\n",
        "  sen = word1\n",
        "  #generate remaining words\n",
        "  while True:\n",
        "    word2=generate_from_trigrams(word0, word1)\n",
        "    if word2 == \"</s>\":\n",
        "      break\n",
        "    sen =sen+\" \" +word2\n",
        "    word1 = word2\n",
        "    word0 = word1\n",
        "\n",
        "  print(sen)\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
